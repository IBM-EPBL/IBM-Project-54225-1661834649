{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3KgB-lMC9yX"
      },
      "outputs": [],
      "source": [
        "#checking the GPU for Model training \n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow \n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "zkZ49iPSEI7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating Sequentials for the classification Model\n",
        "model = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "2nolFe-AEPtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip the Folder in IDLE \n",
        "!unzip \"/content/drive/MyDrive/paper-works /Nalaiya Thiran /Dataset/Final-Dataset.zip\""
      ],
      "metadata": {
        "id": "oNnDThVpESzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the image Size for model Buliding\n",
        "from PIL import Image\n",
        "im = Image.open(\"/content/Final-Dataset/test_set/Apple___Black_rot/01e94c43-0879-4e8c-9b61-c48cfed88dab___JR_FrgE.S 3024.JPG\")\n",
        "print(im.size)"
      ],
      "metadata": {
        "id": "4TdRwZ7qEja7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you wish to resize the image using automated use this code to do (or) using the same image size for the model building\n",
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'E:/DATASET/plant-doc/plantdocx-corn/PlantDoc-Dataset/corn/test/Corn Gray leaf spot'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(f_img)\n",
        "print(\"image are Resized\")"
      ],
      "metadata": {
        "id": "FEscDwIgFgRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 32 feature detectors with 3*3 dimensions so the convolution layer compose of 32 feature maps\n",
        "# 128 by 128 dimensions with colored image(3 channels)  (tensorflow backend)\n",
        "input_size = (256, 256)\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, 3, input_shape = (*input_size, 3), activation = 'relu'))"
      ],
      "metadata": {
        "id": "bamXpWFXGAQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reduce the size of feature maps and therefore reduce the number of nodes in the future fully connected layer (reduce time complexity, less compute intense without losing the performace). 2 by 2 deminsion is the recommended option\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))"
      ],
      "metadata": {
        "id": "ZZt0LpWRGXlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Convolution2D(32, 3, 3, activation = 'relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2, 2)))"
      ],
      "metadata": {
        "id": "wYOszwbDGcrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten all the feature maps in the pooling layer into single vector\n",
        "model.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "KfMuDBqDGe0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making classic ann which compose of fully connected layers\n",
        "# number of nodes in hidden layer (output_dim) (common practice is to take the power of 2)\n",
        "model.add(tf.keras.layers.Dense(units = 64, activation = 'relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(units = 1, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "Wzpcbt9bGgmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the CNN\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "HXZuN4zMGmsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "batch_size = 32\n",
        "# image augmentation part\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# create training set\n",
        "# wanna get higher accuracy -> inccrease target_size\n",
        "training_set = train_datagen.flow_from_directory('/content/Final-Dataset/train_set',\n",
        "                                                 target_size = input_size,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "# create test set\n",
        "# wanna get higher accuracy -> inccrease target_size\n",
        "test_set = test_datagen.flow_from_directory('/content/Final-Dataset/test_set',\n",
        "                                            target_size = input_size,\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'binary')\n",
        "\n",
        "# fit the cnn model to the trainig set and testing it on the test set\n",
        "model.fit(training_set,\n",
        "          steps_per_epoch = 8000/batch_size,\n",
        "          epochs = 5,\n",
        "          validation_data = test_set,\n",
        "          validation_steps = 2000/batch_size)"
      ],
      "metadata": {
        "id": "X23LrA8bGtsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "model.save('CNN_image_Classifer.h5')"
      ],
      "metadata": {
        "id": "MGf1uKrQHA-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}